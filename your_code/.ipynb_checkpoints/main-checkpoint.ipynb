{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "The following table indicates the number of 6-point scores in an American rugby match in the 1979 season.\n",
    "\n",
    "![](table1.png)\n",
    "\n",
    "Based on these results, we create a Poisson distribution with the sample mean parameter  = 2.435. Is there any reason to believe that at a .05 level the number of scores is a Poisson variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import geom\n",
    "from scipy.stats import poisson\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=6.491310681109821, pvalue=0.4836889068537269)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "#6/7/22\n",
    "\n",
    "# mean = lambda\n",
    "#In the poisson the mean should be the same as the parameter, that is 2.435 (mean), so lambda = 2.435.\n",
    "#we know the mean, the experimental mean so we can get the lambda.\n",
    "\n",
    "\n",
    "poisson_pmfs = np.array([poisson(2.435).pmf(i) for i in range(0,7)])\n",
    "poisson_pmfs\n",
    "expected = np.append(poisson_pmfs,1-poisson_pmfs.sum())*448 #we add the >7. 448 is the num of observations\n",
    "st.chisquare([35,99,104,110,62,25,10,3],f_exp=expected) #observed and expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with a pvalue=0.483 at a condifence level of 0.05. If the null is low, we reject the null hyphotesis. So in this case, we\n",
    "#don't reject the null hypothesis and we don't have reason to believe that the data doesn't follow a poisson distribution \n",
    "#with mean 2.435."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS/OPTIONAL - Question 2\n",
    "Let's analyze a discrete distribution. To analyze the number of defective items in a factory in the city of Medellín, we took a random sample of n = 60 articles and observed the number of defectives in the following table:\n",
    "\n",
    "![](table2.png)\n",
    "\n",
    "A poissón distribution was proposed since it is defined for x = 0,1,2,3, .... using the following model:\n",
    "\n",
    "![](image1.png)\n",
    "\n",
    "For some extra insights check the following link: https://online.stat.psu.edu/stat504/node/63/ \n",
    "\n",
    "Does the distribution of defective items follow this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "f_obs=[32,15,0,9,4]\n",
    "mean=(32*0+15*1+0*2+9*3+4*4)/60\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*0+15*1+0*2+9*3+4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.25586482, 12.79803084, 15.58160255, 12.6470674 ,  7.69890228])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.11149256081681616",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28636/4270087450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoisson_pmfs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_exp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#observed and expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36mchisquare\u001b[1;34m(f_obs, f_exp, ddof, axis)\u001b[0m\n\u001b[0;32m   6909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6910\u001b[0m     \"\"\"\n\u001b[1;32m-> 6911\u001b[1;33m     return power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,\n\u001b[0m\u001b[0;32m   6912\u001b[0m                             lambda_=\"pearson\")\n\u001b[0;32m   6913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36mpower_divergence\u001b[1;34m(f_obs, f_exp, ddof, axis, lambda_)\u001b[0m\n\u001b[0;32m   6751\u001b[0m                    \u001b[1;34mf\"of {rtol}, but the percent differences are:\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6752\u001b[0m                    f\"{relative_diff}\")\n\u001b[1;32m-> 6753\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6755\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.11149256081681616"
     ]
    }
   ],
   "source": [
    "poisson_pmfs = np.array([poisson(2.435).pmf(i) for i in range(0,5)])\n",
    "poisson_pmfs\n",
    "#expected = np.append(poisson_pmfs,1-poisson_pmfs.sum())*448 #we add the >7. 448 is the num of observations\n",
    "expected = poisson_pmfs*60\n",
    "display(expected)\n",
    "st.chisquare([32,15,0,9,4],f_exp=expected) #observed and expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes: I am not sure where is my error. Am I calculating correctly the lambda (or mean since they are the same for a \n",
    "#poisson distribution)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "A quality control engineer takes a sample of 10 tires that come out of an assembly line, and would like to verify on the basis of the data that follows, if the number of tires with defects observed over 200 days, if it is true that 5% of all tires have defects (that is, if the sample comes from a binomial population with n = 10 and p = 0.05). \n",
    "\n",
    "![](table3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "n=10\n",
    "p=0.05\n",
    "binomial_dist = binom(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=8.306179519542805, pvalue=0.015715783395950887)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomial_pmfs = np.array([binom(n,p).pmf(i) for i in range(0,2)])\n",
    "expected = np.append(binomial_pmfs,1-binomial_pmfs.sum())*200 \n",
    "st.chisquare([138,53,9],f_exp=expected)\n",
    "#With a confident value of 0.05, since the p-value is .0157 we reject the null hypothesis, that is, that the data follows\n",
    "# a binomial population with n = 10 and p = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "A researcher gathers information about the patterns of Physical Activity of children in the fifth grade of primary school of a public school. He defines three categories of physical activity (Low, Medium, High). He also inquires about the regular consumption of sugary drinks at school, and defines two categories (Yes = consumed, No = not consumed). We would like to evaluate if there is an association between patterns of physical activity and the consumption of sugary drinks for the children of this school, at a level of 5% significance. The results are in the following table: \n",
    "\n",
    "![](table4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.712198008709638,\n",
       " 0.013388412365655075,\n",
       " 3,\n",
       " array([[24.08421053, 19.91578947],\n",
       "        [19.70526316, 16.29473684],\n",
       "        [ 8.21052632,  6.78947368],\n",
       "        [52.        , 43.        ]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer here\n",
    "#We would like to evaluate if there is an association between patterns of physical activity and the consumption of \n",
    "#sugary drinks\n",
    "\n",
    "#The null hypothesis would be that the sugar does NOT influence activity\n",
    "sugar_table=[[32,12],\n",
    "            [14,22],\n",
    "            [6,9],\n",
    "            [52,43]]\n",
    "\n",
    "st.chi2_contingency(np.array(sugar_table))\n",
    "#statistic, p-value, degrees of freedom, expected probs if H0 holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Expected values:\n",
    "[[24.08421053, 19.91578947],\n",
    "        [19.70526316, 16.29473684],\n",
    "        [ 8.21052632,  6.78947368],\n",
    "        [52.        , 43.        ]]\n",
    "        \n",
    " So with a p-value of 0.013388412365655075 at a confidence level of 0.05, we are confident that we reject the null hypothesis       \n",
    "pvalue is low so the null must go. Null hypothesis that sugar doesn't inferfer in the activity. \n",
    "#So sugar interfere in the activity\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
